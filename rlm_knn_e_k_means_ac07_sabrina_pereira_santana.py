# -*- coding: utf-8 -*-
"""RLM KNN e K-Means AC07 SABRINA PEREIRA SANTANA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZdaiR6uhjXjpwlwapCSJaNV3bUMu4VEb

    #VISUALIZAR EXECUÇÃO DO CÓDIGO EM: Gist https://gist.github.com/Sabrina-Pereira-Santana/3cc48fb2c9c7a438a1a5624a9b1af6f3 

    OU

    https://colab.research.google.com/drive/1ZdaiR6uhjXjpwlwapCSJaNV3bUMu4VEb?usp=sharing
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

df1 = pd.read_csv('https://github.com/danieltb3006/DM_Ibmec/raw/main/base_1_Ecommerce_Customers.csv',sep=',')
df1

df1.info()

df=df1.filter(items=['Avg. Session Length','Time on App','Time on Website',
       'Length of Membership','Yearly Amount Spent'])

df.info()

correlation_matrix = df.corr()

plt.figure(figsize=(6, 4))  # Adjust figure size if needed
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Correlation Heatmap for Yearly Amount Spent')
plt.show()

"""REGRESSÃO LINEAR SIMPLES"""

X1 = df[['Length of Membership']]
y1 = df['Yearly Amount Spent']

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error


X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.3, random_state=0)
modelo1 = LinearRegression()
modelo1.fit(X1_train, y1_train)

print('Coeficiente:', modelo1.coef_)
print('Intercepto:', modelo1.intercept_)

y1_pred = modelo1.predict(X1_test)

mse = mean_squared_error(y1_test, y1_pred)
rmse = np.sqrt(mse)
mae = mean_absolute_error(y1_test, y1_pred)
r2 = r2_score(y1_test, y1_pred)

metricas = pd.DataFrame({
    'Métrica': ['MSE', 'RMSE', 'MAE', 'R²'],
    'Valor': [mse, rmse, mae, r2]
})
print(metricas)

print('\nR-quadrado:', r2)

def prever_gasto(length_of_membership):
  """
  Prediz o gasto anual com base no tempo de associação, formatado em dólar.

  Args:
    length_of_membership: Tempo de associação do cliente.

  Returns:
    O gasto anual previsto, formatado em dólar.
  """
  coeficiente1 = modelo1.coef_[0]
  intercepto1 = modelo1.intercept_
  gasto_previsto = coeficiente1 * length_of_membership + intercepto1

  # Formata o gasto previsto como dólar
  gasto_formatado = '${:,.2f}'.format(gasto_previsto)

  return gasto_formatado

tempo_associacao = 5
gasto_previsto = prever_gasto(tempo_associacao)
print(f"Gasto previsto para {tempo_associacao} anos de associação: {gasto_previsto}")

"""REGRESSÃO LINEAR MÚLTIPLA"""

X2 = df[['Avg. Session Length', 'Time on App', 'Time on Website', 'Length of Membership']]
y2 = df['Yearly Amount Spent']

from sklearn.model_selection import train_test_split

X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.3, random_state=101)

from sklearn.linear_model import LinearRegression
modelo2 = LinearRegression()  # Criando uma instância do modelo LinearRegression
modelo2.fit(X2_train, y2_train)  # Treinando o modelo com os dados de treinamento

# Exibindo os coeficientes e o intercepto
print('Coeficientes:', modelo2.coef_)
print('Intercepto:', modelo2.intercept_)

def prever_gasto_multiplo(avg_session_length, time_on_app, time_on_website, length_of_membership):
  """
  Prediz o gasto anual com base em múltiplas variáveis, formatado em dólar.

  Args:
    avg_session_length: Duração média da sessão.
    time_on_app: Tempo gasto no aplicativo.
    time_on_website: Tempo gasto no site.
    length_of_membership: Tempo de associação do cliente.

  Returns:
    O gasto anual previsto, formatado em dólar.
  """
  coeficientes2 = modelo2.coef_  # Corrigido para usar modelo2.coef_
  intercepto2 = modelo2.intercept_  # Corrigido para usar modelo2.intercept_

  gasto_previsto2 = (
      coeficientes2[0] * avg_session_length +
      coeficientes2[1] * time_on_app +
      coeficientes2[2] * time_on_website +
      coeficientes2[3] * length_of_membership +
      intercepto2
  )

  # Formata o gasto previsto como dólar
  gasto_formatado2 = '${:,.2f}'.format(gasto_previsto2)

  return gasto_formatado2

from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error

# Fazendo predições com o modelo treinado
y2_pred = modelo2.predict(X2_test)

# Calculando as métricas de avaliação
mse2 = mean_squared_error(y2_test, y2_pred)
rmse2 = np.sqrt(mse)
mae2 = mean_absolute_error(y2_test, y2_pred)
r22 = r2_score(y2_test, y2_pred)

# Criando o quadro com as métricas
metricas2 = pd.DataFrame({
    'Métrica': ['MSE', 'RMSE', 'MAE', 'R²'],
    'Valor': [mse2, rmse2, mae2, r22]
})

# Mostrando o quadro com as métricas
print(metricas2)

# Mostrando o R-quadrado
print('\nR-quadrado:', r22)

"""K-MEANS"""

import pandas as pd
import numpy as np
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt

# Select features for clustering
features = ['Avg. Session Length', 'Time on App', 'Time on Website', 'Length of Membership', 'Yearly Amount Spent']
X = df[features]

# Scale the data
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

wcss = []  # Within-cluster sum of squares

for i in range(1, 26):  # Check for k values from 1 to 25
    kmeans = KMeans(n_clusters=i, random_state=42)  # Initialize KMeans Qual random state devo utilizar?
    kmeans.fit(X_scaled)  # Fit the model
    wcss.append(kmeans.inertia_)  # Append the inertia (WCSS)

# Plot the Elbow graph
plt.plot(range(1, 26), wcss, marker='o')
plt.title('Elbow Method for Optimal k')
plt.xlabel('Number of Clusters (k)')
plt.ylabel('WCSS')
plt.show()

"""Próximo do 5 parece um ángulo mais agudo"""

# Assuming X_scaled is your scaled data from previous steps
kmeans = KMeans(n_clusters=3, random_state=42)  # Initialize KMeans with 3 clusters
kmeans.fit(X_scaled)  # Fit the model to your scaled data
labels = kmeans.labels_  # Get cluster labels for each data point

df['Cluster'] = labels  # Add the cluster labels to your DataFrame

# Assuming you want to visualize clusters based on 'Avg. Session Length' and 'Yearly Amount Spent'
plt.figure(figsize=(6, 4))
plt.scatter(df['Avg. Session Length'], df['Yearly Amount Spent'], c=df['Cluster'], cmap='viridis')
plt.xlabel('Avg. Session Length')
plt.ylabel('Yearly Amount Spent')
plt.title('Customer Segmentation with K-Means (3 Clusters)')
plt.show()

import pandas as pd
import numpy as np

# ... (seu código anterior para K-Means e obtenção de 'X_scaled', 'kmeans', etc.) ...

# Obtém os centros dos clusters
cluster_centers = kmeans.cluster_centers_

# Cria uma lista para armazenar os clusters atribuídos a cada indivíduo
cluster_assignments = []

# Itera sobre cada ponto de dados em X_scaled
for i in range(X_scaled.shape[0]):
    # Calcula as distâncias entre o ponto de dados atual e todos os centros dos clusters
    distances = np.sqrt(np.sum((X_scaled[i] - cluster_centers)**2, axis=1))

    # Encontra o índice do centro do cluster mais próximo
    closest_cluster = np.argmin(distances)

    # Adiciona o cluster atribuído à lista
    cluster_assignments.append(closest_cluster)

# Adiciona uma nova coluna ao DataFrame 'df' com as atribuições de cluster
df['Cluster_Assigned'] = cluster_assignments

# --- Testes e exemplos de uso ---

# 1. Imprimir os primeiros 5 registros do DataFrame com a coluna 'Cluster_Assigned':
print(df.head())

# 2. Contar quantos indivíduos pertencem a cada cluster:
print(df['Cluster_Assigned'].value_counts())

# 3. Filtrar o DataFrame para mostrar apenas os indivíduos do cluster 0:
cluster_0_df = df[df['Cluster_Assigned'] == 0]
print(cluster_0_df.head())

# 4. Calcular a média dos gastos anuais ('Yearly Amount Spent') para cada cluster:
cluster_spending_means = df.groupby('Cluster_Assigned')['Yearly Amount Spent'].mean()
print(cluster_spending_means)

# ... (outros testes e análises que você desejar) ...

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score

# ... (seu código anterior para carregar os dados, preparar 'df', etc.) ...

# --- KNN para previsão de cluster ---

# 1. Preparar os dados para o KNN
X3 = df[['Avg. Session Length', 'Time on App', 'Time on Website', 'Length of Membership', 'Yearly Amount Spent']]
y3 = df['Cluster']  # Usando a coluna 'Cluster' como alvo
X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, test_size=0.30, random_state=0)

# Escalar os dados (importante para o KNN)
scaler3 = StandardScaler()
X3_train = scaler3.fit_transform(X3_train)
X3_test = scaler3.transform(X3_test)

# 2. Encontrar o melhor valor de k
best_k3 = 0
best_accuracy3 = 0

for k in range(5, 50):
    knn3 = KNeighborsClassifier(n_neighbors=k)
    knn3.fit(X3_train, y3_train)
    y3_pred = knn3.predict(X3_test)
    accuracy3 = accuracy_score(y3_test, y3_pred)

    if accuracy3 > best_accuracy3:
        best_accuracy3 = accuracy3
        best_k3 = k

print(f"Melhor valor de k para KNN: {best_k3}, com acurácia: {best_accuracy3}")

# 3. Criar a função de previsão
def predict_cluster3(new_customer_data):
    """
    Prediz o cluster para um novo cliente usando o modelo KNN.
    """
    scaled_data = scaler3.transform([new_customer_data])  # Usar scaler3
    predicted_cluster3 = knn3.predict(scaled_data)[0]
    return predicted_cluster3

# 4. Analisar os novos clientes
new_customers3 = [
    [34.0, 12.5, 37.0, 4.5, 550.0],
    [32.0, 13.0, 38.0, 3.0, 600.0],
    [33.5, 11.0, 36.5, 5.0, 575.0]
]

# Classificar os clusters por popularidade
cluster_counts = df['Cluster'].value_counts()
bronze_cluster3 = cluster_counts.idxmax()
gold_cluster3 = cluster_counts.idxmin()
silver_cluster3 = cluster_counts.drop([bronze_cluster3, gold_cluster3]).idxmax()

# Prever os clusters para os novos clientes
for i, customer_data in enumerate(new_customers3):
    predicted_cluster3 = predict_cluster3(customer_data)

    if predicted_cluster3 == bronze_cluster3:
        cluster_name = "Bronze"
    elif predicted_cluster3 == gold_cluster3:
        cluster_name = "Ouro"
    else:
        cluster_name = "Prata"

    print(f"Novo cliente {i+1} deve ser alocado ao Cluster {cluster_name}")

"""Com o **for k in range** já foi possível encontrar o melhor k, mesmo assim vamos verificar no gráfico"""

import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np

# ... (seu código anterior para o KNN, incluindo a busca pelo melhor k) ...

# Criar listas para armazenar os valores de k e as acurácias correspondentes
k_values = []
accuracies = []

# Loop para testar diferentes valores de k e calcular as acurácias
for k in range(5, 50):
    knn3 = KNeighborsClassifier(n_neighbors=k)
    knn3.fit(X3_train, y3_train)
    y3_pred = knn3.predict(X3_test)
    accuracy3 = accuracy_score(y3_test, y3_pred)

    k_values.append(k)
    accuracies.append(accuracy3)

# Criar o gráfico de barras
sns.set_theme(style="darkgrid")
plt.figure(figsize=(6, 5))
clrs = ['grey' if (x < max(accuracies)) else 'red' for x in accuracies]  # Destacar a melhor acurácia em vermelho
ax = sns.barplot(x=accuracies, y=k_values, orient='h', legend=False, palette=clrs)
ax.set(xlabel='Acurácia', ylabel='Valor de k')
plt.title('Acurácia do KNN para diferentes valores de k')  # Adicionar um título ao gráfico
plt.show()
